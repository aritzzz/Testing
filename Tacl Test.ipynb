{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_encoder import *\n",
    "import itertools as it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'classobj'>\n",
      "['', '../models/', '..', '/home/tirthankar/miniconda3/envs/jcdl/lib/python27.zip', '/home/tirthankar/miniconda3/envs/jcdl/lib/python2.7', '/home/tirthankar/miniconda3/envs/jcdl/lib/python2.7/plat-linux2', '/home/tirthankar/miniconda3/envs/jcdl/lib/python2.7/lib-tk', '/home/tirthankar/miniconda3/envs/jcdl/lib/python2.7/lib-old', '/home/tirthankar/miniconda3/envs/jcdl/lib/python2.7/lib-dynload', '/home/tirthankar/.local/lib/python2.7/site-packages', '/home/tirthankar/miniconda3/envs/jcdl/lib/python2.7/site-packages', '/home/tirthankar/miniconda3/envs/jcdl/lib/python2.7/site-packages/IPython/extensions', '/home/tirthankar/.ipython']\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group reviews into sets of 3, each set for one paper\n",
    "def collate(reviews):\n",
    "    iters = [iter(reviews)]*3\n",
    "    return np.array(map(lambda x:list(x), zip(*iters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_padded_, label_scale_, aspects_ = predict1.prepare_data('../../data/iclr_2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (papers, paper obj, reviews_all, review, no.reviews, reviews, decision), aspects_score = datapadded\n",
    "\n",
    "# All papers should have only 3 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(papers,paper_obj,reviews_all,_,revs_count,_,decision),_ = data_padded_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_all = list(it.chain.from_iterable(reviews_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2727"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-768888694c02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreviews_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/tirthankar/Rajeev/JCDL/peer-read/PeerRead-master/code/tacl/sentence_encoder.pyc\u001b[0m in \u001b[0;36membed\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total sentences to be embedded: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tirthankar/Rajeev/JCDL/peer-read/PeerRead-master/code/tacl/sentence_encoder.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tirthankar/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tirthankar/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tirthankar/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tirthankar/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tirthankar/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tirthankar/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reviews_embedded = embed(reviews_all[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2727, 159, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_embedded = embed(papers[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = embed(papers[400:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe1 = embed(papers[600:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(papers_embedded.shape)\n",
    "print(pe.shape)\n",
    "print(pe1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 1494, 512)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = np.pad(pe, [(0,0),(0, 1494-1250), (0,0)], mode = 'constant', constant_values=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_embedded = np.pad(papers_embedded, [(0,0),(0, 1494-835), (0,0)], mode = 'constant', constant_values=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_emb = np.concatenate((papers_embedded, pe, pe1), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(909, 1494, 512)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = collate(reviews_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(909, 3, 159, 512)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revs = np.array(revs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = np.array(decision).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(909,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net, self).__init__()\n",
    "        \n",
    "        num_classes = 2\n",
    "        \n",
    "        self.p = nn.Sequential(\n",
    "                            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 5),\n",
    "                            nn.ReLU()\n",
    "                            )\n",
    "        self.r = nn.Sequential(\n",
    "                            nn.Conv1d(in_channels = 512, out_channels = 64, kernel_size = 5),\n",
    "                            nn.ReLU()\n",
    "                            )\n",
    "    \n",
    "        #self.s1 = nn.Linear(4*525,rh1)\n",
    "\n",
    "        self.l1 = nn.Linear(256, 100)\n",
    "        \n",
    "        self.l2 = nn.Linear(64,100)\n",
    "        \n",
    "        self.crossLinear = nn.Linear(100,100)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "        self.l3 = nn.Linear(400,200)\n",
    "        self.l4 = nn.Linear(200,100)\n",
    "        self.l5 = nn.Linear(100, num_classes)\n",
    "        \n",
    "#         self.multihead_attn = nn.MultiheadAttention(100, 1)\n",
    "        \n",
    "#         self.l3 = nn.Linear(2*100,100)\n",
    "#         self.l4 = nn.Linear(100, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p = 0.7)\n",
    "        \n",
    "    def forward(self, paper, review, sentiment):  \n",
    "        batch_size = paper.shape[0]\n",
    "        r1, r2, r3 = review\n",
    "        out_p = self.p(paper)\n",
    "        out_p = F.max_pool1d(out_p, out_p.shape[2])\n",
    "\n",
    "        out_r1 = self.r(r1)\n",
    "        out_r1 = F.max_pool1d(out_r1, out_r1.shape[2])    #out_p/r shape = (batch_size, #filters, 1)\n",
    "        \n",
    "        out_r2 = self.r(r2)\n",
    "        out_r2 = F.max_pool1d(out_r2, out_r2.shape[2])    #out_p/r shape = (batch_size, #filters, 1)\n",
    "        \n",
    "        out_r3 = self.r(r3)\n",
    "        out_r3 = F.max_pool1d(out_r3, out_r3.shape[2])    #out_p/r shape = (batch_size, #filters, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         print out_p.view(batch_size, -1).shape\n",
    "#         print out_r1.shape\n",
    "        \n",
    "#         out = torch.cat((out_p3, out_r3), dim = 1)         #out shape = (batch_size, num_filters*kernels, 1)\n",
    "#        out = out_r3\n",
    "        \n",
    "        #r = self.s1(sentiment.view(batch_size, -1))\n",
    "        #r = self.dropout(r)\n",
    "        out_p = self.l1(out_p.view(batch_size,-1))\n",
    "        out_r1 = self.l2(out_r1.view(batch_size,-1))\n",
    "        out_r2 = self.l2(out_r2.view(batch_size,-1))\n",
    "        out_r3 = self.l2(out_r3.view(batch_size,-1))\n",
    "        \n",
    "        query = out_p\n",
    "        key1, key2, key3 = out_r1, out_r2, out_r3\n",
    "        \n",
    "        keys = torch.stack([key1, key2, key3], dim=1)  #keys shape = (batch_size, 3, dim)\n",
    "#         print keys.shape\n",
    "        BilinearAttn = torch.bmm(self.crossLinear(query).unsqueeze(1), keys.transpose(1,2))\n",
    "#         print BilinearAttn.shape\n",
    "        attnWts = self.softmax(BilinearAttn)   #attnWts shape = (batch_size,1,3)\n",
    "    \n",
    "    \n",
    "        values = attnWts.transpose(1,2)*keys\n",
    "#         print values.shape\n",
    "        \n",
    "        values = values.view(batch_size, -1)\n",
    "        \n",
    "        cross = torch.cat((out_p, values), dim = 1)\n",
    "        \n",
    "        \n",
    "        out = self.relu(self.l3(cross))\n",
    "        out = self.relu(self.l4(out))\n",
    "        out = self.l5(out)\n",
    "        \n",
    "        \n",
    "        #out = self.l1(out.view(batch_size, -1))\n",
    "        #out = self.dropout(out)\n",
    "        \n",
    "    \n",
    "        \n",
    "        return out, attnWts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dset(Dataset):\n",
    "    def __init__(self, data, y_data):\n",
    "        x1, x2 = data\n",
    "        print x1.shape\n",
    "        print x2.shape\n",
    "        assert x1.shape[0] == x2.shape[0]\n",
    "        self.len = x1.shape[0]\n",
    "        self.x1_data = x1\n",
    "        self.x2_data = x2\n",
    "        self.y_data = y_data\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x1_data[index,:,:], self.x2_data[index,:,:,:]), self.y_data[index] #, self.x3_data[index,:,:]), self.y_data[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(Dset, batch_size, num_workers):\n",
    "    loader = DataLoader(Dset, batch_size = batch_size, shuffle = False, num_workers = num_workers)\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainD = dset((papers_emb, rev), decision)\n",
    "trainloader = load_data(trainD, batch_size = 20, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters()) #,weight_decay = 0.0, momentum = 0.9, lr = 0.009)\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-3dcd20745fde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mpaper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m   \u001b[0;31m#paper = (batch_size, seq_len, dim) #revs = (batch_size, 3 , seq_len, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpaper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mrev1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrevs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mrev2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrevs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    for i, data in enumerate(trainloader,0):\n",
    "        (paper, revs), decs = data   #paper = (batch_size, seq_len, dim) #revs = (batch_size, 3 , seq_len, dim)\n",
    "        paper = paper.transpose(1,2).float()\n",
    "        rev1 = revs[:,0,:,:].transpose(1,2).float()\n",
    "        rev2 = revs[:,1,:,:].transpose(1,2).float()\n",
    "        rev3 = revs[:,2,:,:].transpose(1,2).float()\n",
    "        out, attnWts = model(paper, (rev1, rev2, rev3),_)\n",
    "#        print attnWts\n",
    "#         print decision\n",
    "#         print out\n",
    "#         print out\n",
    "        pred = (torch.max(out, 1)[1].view(decs.size()).data == decs.data).sum()\n",
    "#         print pred\n",
    "        acc = (pred.item()/decs.size()[0])\n",
    "        optimizer.zero_grad()\n",
    "        los = loss(out,decs)\n",
    "        los.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss.append(los.item())\n",
    "        epoch_acc.append(acc)\n",
    "#         break\n",
    "    print(\"Epoch:{}, Loss:{}, Acc:{}\".format(epoch,np.average(epoch_loss),np.average(epoch_acc)))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p = papers_emb[:10,:,:]\n",
    "test_r = rev[:10,:,:,:]\n",
    "test_d = decision[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "testD = dset((test_p, test_r), test_d)\n",
    "testloader = load_data(testD, batch_size = 10, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in testloader:\n",
    "    (p, r), d = data\n",
    "    pt = p.transpose(1,2).float()\n",
    "    rt1 = r[:,0,:,:].transpose(1,2).float()\n",
    "    rt2 = r[:,1,:,:].transpose(1,2).float()\n",
    "    rt3 = r[:,2,:,:].transpose(1,2).float()\n",
    "    out_t, attnWts_t = model(pt, (rt1, rt2, rt3),_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[8.2664e-01, 5.5302e-02, 1.1806e-01]],\n",
       "\n",
       "        [[9.9929e-01, 5.7948e-07, 7.0773e-04]],\n",
       "\n",
       "        [[6.1960e-02, 9.1830e-01, 1.9742e-02]],\n",
       "\n",
       "        [[5.9085e-03, 9.7904e-01, 1.5055e-02]],\n",
       "\n",
       "        [[9.1499e-02, 8.9191e-01, 1.6596e-02]],\n",
       "\n",
       "        [[3.5793e-02, 7.5099e-01, 2.1322e-01]],\n",
       "\n",
       "        [[2.3788e-04, 4.8013e-01, 5.1963e-01]],\n",
       "\n",
       "        [[2.8056e-02, 6.8387e-01, 2.8807e-01]],\n",
       "\n",
       "        [[8.3396e-01, 1.4250e-03, 1.6462e-01]],\n",
       "\n",
       "        [[7.7019e-01, 1.5070e-01, 7.9109e-02]]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attnWts_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'APPROPRIATENESS': None,\n",
       "  'CLARITY': None,\n",
       "  'COMMENTS': u'In this paper the authors present a model for more accurate Netflix recommendations (rating predictions, RMSE).  In particular, the authors demonstrate that a deep autoencoder, carefully tuned, can out-perform  more complex RNN-based models that have temporal information.  The authors examine how different non-linear activations, model size, dropout, and a novel technique called \"dense re-feeding\" can together improve DNN-based collaborative filtering.  Pros: - The accuracy results are impressive and a useful datapoint in how to build a DNN-based recommender.   - The dense re-feeding technique seems to be novel with incremental (but meaningful) benefits.    Cons: - Experimental results on only one dataset.  - Difficult to know if the results are generalizable.  ',\n",
       "  'DATE': None,\n",
       "  'IMPACT': None,\n",
       "  'IS_ANNOTATED': None,\n",
       "  'IS_META_REVIEW': None,\n",
       "  'MEANINGFUL_COMPARISON': None,\n",
       "  'ORIGINALITY': None,\n",
       "  'OTHER_KEYS': None,\n",
       "  'PRESENTATION_FORMAT': None,\n",
       "  'RECOMMENDATION': 6,\n",
       "  'RECOMMENDATION_UNOFFICIAL': None,\n",
       "  'REPLICABILITY': None,\n",
       "  'REVIEWER_CONFIDENCE': None,\n",
       "  'SOUNDNESS_CORRECTNESS': None,\n",
       "  'SUBSTANCE': None,\n",
       "  'TITLE': None},\n",
       " {'APPROPRIATENESS': None,\n",
       "  'CLARITY': None,\n",
       "  'COMMENTS': u'This paper proposed to use deep AE to do rating prediction tasks in recommender systems. Some of the conclusions of the paper, e.g. deep models perform bettern than shallow ones, the non-linear activation function is important, dropout is necessary to prevent overfitting, are well known, and hence is of less novelty. The proposed re-feeding algorithm to overcome natural sparseness of CF is interesting, however, I don\\'t think it is enough to support being accepted by ICLR.  Some reference about rating prediction are missing, such as \"A neural autoregressive approach to collaborative filtering, ICML2016\". And it would be better to show the performance of the model on implicit rating data, since it is more desirable in practice, since many industry applications have only implicit rating (e.g. whether the user watches the movie or not.).',\n",
       "  'DATE': None,\n",
       "  'IMPACT': None,\n",
       "  'IS_ANNOTATED': None,\n",
       "  'IS_META_REVIEW': None,\n",
       "  'MEANINGFUL_COMPARISON': None,\n",
       "  'ORIGINALITY': None,\n",
       "  'OTHER_KEYS': None,\n",
       "  'PRESENTATION_FORMAT': None,\n",
       "  'RECOMMENDATION': 3,\n",
       "  'RECOMMENDATION_UNOFFICIAL': None,\n",
       "  'REPLICABILITY': None,\n",
       "  'REVIEWER_CONFIDENCE': None,\n",
       "  'SOUNDNESS_CORRECTNESS': None,\n",
       "  'SUBSTANCE': None,\n",
       "  'TITLE': None},\n",
       " {'APPROPRIATENESS': None,\n",
       "  'CLARITY': None,\n",
       "  'COMMENTS': u'This paper presents a deep autoencoder model for rating prediction. The autoencoder takes the user\\u2019s rating over all the items as input and tries to predict the observed ratings in the output with mean squared error. A few techniques are applied to make the training feasible without layer-wise pre-training: 1) SELU activation. 2) dropout with high probability. 3) dense output re-feeding. On the Netflix prize dataset, the proposed deep autoencoder outperforms other state-of-the-art approaches.   Overall, the paper is easy to follow. However, I have three major concerns regarding the paper that makes me decide to reject it.  1. Lack of novelty. The paper is essentially a deeper version of the U-AutoRec (Sedhain et al. 2015) with a few recently emerged innovations in deep learning. The dense output re-feeding is not something particularly novel, it is more or less a data-imputation procedure with expectation-maximization \\u2014 in fact if the authors intend to seek explanation for this output re-feeding technique, EM might be one of the interpretations. And similar technique (more theoretically grounded) has been applied in image imputation for variational autoencoder (Rezende et al. 2014, Stochastic Backpropagation and Approximate Inference in Deep Generative Models).   2. The experimental setup is also worth questioning. Using a time-split dataset is of course more challenging. However, the underlying assumption of autoencoders (or more generally, latent factor models like matrix factorization) is the all the ratings are exchangeable (conditionally independent given the latent representations), i.e., autoencoders/MF are not capable of inferring the temporal information from the data, Thus it is not even a head-to-head comparison with a temporal model (e.g., RNN in Wu et al. 2017). Of course you can still apply a static autoencoder to time-split data, but what ends up happening is the model will use its capacity to try to explain the temporal signal in the data \\u2014 a deeper model certainly has more extra capacity to do so. I would suggest the authors comparing on a non-time-split dataset with other static models, like I(U)-AutoRec/MF/CF-NADE (Zheng et al. 2016)/etc.    3. Training deep models on recommender systems data is impressive. However, I would like to suggest we, as a community, start to step away from the task of rating predictions as much as we can, especially in more machine-learning-oriented venues (NIPS, ICML, ICLR, etc.) where the reviewers might be less aware of the shift in recommender systems research. (The task of rating predictions was made popular mostly due to the Netflix prize, yet even Netflix itself has already moved on from ratings.) Training (and evaluating) with RMSE on the observed ratings assumes all the missing ratings are missing at random, which is clearly far from realistic for recommender systems (see Marlin et al. 2007, Collaborative Filtering and the Missing at Random Assumption). In fact, understanding why some of the ratings are missing presents a unique challenge for the recommender systems. See, e.g., Steck 2010, Training and testing of recommender systems on data missing not at random, Liang et al. 2016, Modeling user exposure in recommendation, Schnabel et al. 2016, Recommendations as Treatments: Debiasing Learning and Evaluation. A model with good RMSE in a lot of cases does not translate to good recommendations (Cremonesi et al. 2010, Performance of recommender algorithms on top-n recommendation tasks ). As a first step, at least start to use all the 0\\u2019s in the form of implicit feedback and focus on ranking-based metrics other than RMSE. ',\n",
       "  'DATE': None,\n",
       "  'IMPACT': None,\n",
       "  'IS_ANNOTATED': None,\n",
       "  'IS_META_REVIEW': None,\n",
       "  'MEANINGFUL_COMPARISON': None,\n",
       "  'ORIGINALITY': None,\n",
       "  'OTHER_KEYS': None,\n",
       "  'PRESENTATION_FORMAT': None,\n",
       "  'RECOMMENDATION': 4,\n",
       "  'RECOMMENDATION_UNOFFICIAL': None,\n",
       "  'REPLICABILITY': None,\n",
       "  'REVIEWER_CONFIDENCE': None,\n",
       "  'SOUNDNESS_CORRECTNESS': None,\n",
       "  'SUBSTANCE': None,\n",
       "  'TITLE': None}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[review.__dict__ for review in paper_obj[6].__dict__['REVIEWS']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
